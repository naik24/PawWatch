{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install av","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-27T18:02:42.846228Z","iopub.execute_input":"2024-10-27T18:02:42.846735Z","iopub.status.idle":"2024-10-27T18:02:56.984430Z","shell.execute_reply.started":"2024-10-27T18:02:42.846693Z","shell.execute_reply":"2024-10-27T18:02:56.983515Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting av\n  Downloading av-13.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\nDownloading av-13.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.1/33.1 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: av\nSuccessfully installed av-13.1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import av\nimport torch\nimport numpy as np\nfrom transformers import VideoLlavaForConditionalGeneration, VideoLlavaProcessor\nfrom huggingface_hub import hf_hub_download","metadata":{"execution":{"iopub.status.busy":"2024-10-27T18:15:31.156060Z","iopub.execute_input":"2024-10-27T18:15:31.157062Z","iopub.status.idle":"2024-10-27T18:15:31.161802Z","shell.execute_reply.started":"2024-10-27T18:15:31.157015Z","shell.execute_reply":"2024-10-27T18:15:31.160816Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def read_video_pyav(container, indices):\n    '''\n    Decode the video with PyAV decoder.\n    Args:\n        container (`av.container.input.InputContainer`): PyAV container.\n        indices (`List[int]`): List of frame indices to decode.\n    Returns:\n        result (np.ndarray): np array of decoded frames of shape (num_frames, height, width, 3).\n    '''\n    frames = []\n    container.seek(0)\n    start_index = indices[0]\n    end_index = indices[-1]\n    for i, frame in enumerate(container.decode(video=0)):\n        if i > end_index:\n            break\n        if i >= start_index and i in indices:\n            frames.append(frame)\n    return np.stack([x.to_ndarray(format=\"rgb24\") for x in frames])","metadata":{"execution":{"iopub.status.busy":"2024-10-27T18:03:52.669535Z","iopub.execute_input":"2024-10-27T18:03:52.670586Z","iopub.status.idle":"2024-10-27T18:03:52.677078Z","shell.execute_reply.started":"2024-10-27T18:03:52.670539Z","shell.execute_reply":"2024-10-27T18:03:52.676122Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Load the model in half-precision\nmodel = VideoLlavaForConditionalGeneration.from_pretrained(\"LanguageBind/Video-LLaVA-7B-hf\", torch_dtype=torch.float16, device_map=\"auto\")\nprocessor = VideoLlavaProcessor.from_pretrained(\"LanguageBind/Video-LLaVA-7B-hf\")","metadata":{"execution":{"iopub.status.busy":"2024-10-27T18:05:33.024841Z","iopub.execute_input":"2024-10-27T18:05:33.025665Z","iopub.status.idle":"2024-10-27T18:14:15.209880Z","shell.execute_reply.started":"2024-10-27T18:05:33.025621Z","shell.execute_reply":"2024-10-27T18:14:15.209065Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fc7b73ca5dd4c6fa551de284bc84d83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/112k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8700a6e283114f6d970e989dbbb946fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc6d9788063e4d77aca71fc0d66fd16f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"513f2c92d8b9477cb5d020eb9c98dc54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68245c6a1fe34f328613c7cccbf024bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.81G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de4a78db62cc4d7e8464c63cd420ded1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a1fb4cec7ef48e7aaf14fa5ebcaed9c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/148 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf6f193bdad943cfbc7141b0089d59d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/890 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c60fe39cf594ed4b1b4afbf7c2a2dfb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.59k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e931b33e7e89414ea33ab4ca34629ed4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcd230b5f0ab41f7bc3d518b9497012b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bf61b2b705249af99a41bdd2eae068a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/66.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fd59da5c62b4073bf1d1dadcf13ec1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/582 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ab70b1d65a048a49e623ee9c360f9a4"}},"metadata":{}}]},{"cell_type":"code","source":"!pip install huggingface_hub","metadata":{"execution":{"iopub.status.busy":"2024-10-27T18:14:43.932458Z","iopub.execute_input":"2024-10-27T18:14:43.933158Z","iopub.status.idle":"2024-10-27T18:14:56.020715Z","shell.execute_reply.started":"2024-10-27T18:14:43.933103Z","shell.execute_reply":"2024-10-27T18:14:56.019436Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.25.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.15.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2024.6.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0.2)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.8.30)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the video as an np.arrau, sampling uniformly 8 frames\nvideo_path = hf_hub_download(repo_id=\"nprasad24/voxel51-test\", filename=\"Dog1.mp4\", repo_type=\"dataset\")\ncontainer = av.open(video_path)\ntotal_frames = container.streams.video[0].frames\nindices = np.arange(0, total_frames, total_frames / 8).astype(int)\nvideo = read_video_pyav(container, indices)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T18:28:16.557710Z","iopub.execute_input":"2024-10-27T18:28:16.558578Z","iopub.status.idle":"2024-10-27T18:28:17.296903Z","shell.execute_reply.started":"2024-10-27T18:28:16.558534Z","shell.execute_reply":"2024-10-27T18:28:17.295907Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"Dog1.mp4:   0%|          | 0.00/158k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfe16cd38e564ac6a19c74c57e5e5007"}},"metadata":{}}]},{"cell_type":"code","source":"# For better results, we recommend to prompt the model in the following format\nprompt = \"USER: <video>\\nPerform detailed animal action recognition on the video. ASSISTANT:\"\ninputs = processor(text=prompt, videos=video, return_tensors=\"pt\")","metadata":{"execution":{"iopub.status.busy":"2024-10-27T18:28:20.733712Z","iopub.execute_input":"2024-10-27T18:28:20.734451Z","iopub.status.idle":"2024-10-27T18:28:20.779486Z","shell.execute_reply.started":"2024-10-27T18:28:20.734407Z","shell.execute_reply":"2024-10-27T18:28:20.778725Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"out = model.generate(**inputs, max_new_tokens=60)\nprocessor.batch_decode(out, skip_special_tokens=True, clean_up_tokenization_spaces=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T18:28:22.902518Z","iopub.execute_input":"2024-10-27T18:28:22.902958Z","iopub.status.idle":"2024-10-27T18:28:32.568238Z","shell.execute_reply.started":"2024-10-27T18:28:22.902913Z","shell.execute_reply":"2024-10-27T18:28:32.567280Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"[\"USER: \\nPerform detailed animal action recognition on the video. ASSISTANT: In the video, a dog is seen standing in a cage and biting its own paw. The dog appears to be in distress or discomfort, as it is biting its paw repeatedly. The dog's behavior suggests that it might be experiencing some sort of pain\"]"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}